from pathlib import Path
from typing import Any, Dict, Tuple, Union

import tensorflow as tf
from tensorflow import Tensor

from fasterrcnn.utils.data_utils.tfds_utils import modify_image_size

from .backbone.factory import get_backbone
from .detection import Detector
from .rpn import RPN
from .utils.bbox_utils import decode, encode
from .utils.data_utils.data_utils import display_image
from .utils.nms_utils import apply_nms, per_class_nms
from .utils.proposals_utils import filter_proposals
from .utils.roi_pooling_utils import roi_pooling
from .utils.rpn_anchors_utils import generate_anchors


class FRCNN:
    """The faster rcnn algorithm

    Attributes:
        cfg (Dict[str, Any]): The config used to create all sub-networks/models
        backbone (Backbone): The backbone model for feature extraction
        rpn (RPN):  The region proposal network
        detector (Detector): The detector, performs object detection on regions
         generated by RPN
    """

    def __init__(self, config: Dict[str, Any]):
        """Initialize a faster rcnn model. This creates the backbone, rpn and detector
        and stores the required configs in memeory

        Args:
            config (Dict[str, Any]): Config settings required to create the necessary
            sub-networks/model of faster rcnn
        """
        self.cfg = config
        self.backbone, _, _ = get_backbone(config["rpn"]["backbone"])
        self.rpn = RPN(config["rpn"])
        self.detector = Detector(config["detector"])

    def _create_image_input(self, file_path: Union[str, Path]) -> Tensor:
        """Create an image given the path

        Args:
            file_path (Union[str, Path]): image path

        Returns:
            Tensor: Loaded image
        """
        image = tf.io.read_file(file_path)
        image = tf.io.decode_image(image)

        image, _, _ = modify_image_size(image, self.cfg["image_base_size"])
        image = tf.cast(image, tf.int32)[:, :, :3]

        return image

    def __call__(self, x: Tensor) -> Tuple[Tensor, Tensor]:
        """Given an input Tensor, x, obtain object bounding boxes,  labels, class scores

        Args:
            x (Tensor): The input Tensor of an image for which objects are to be
             detected. 3-D float32 Tensor. If 4-D then the first dimension (batch)
             must be 1

        Raises:
            Exception: When batch dimension is greater than 1
            Exception: When input Tensor is not a 3-D or 4-D float32 Tensor

        Returns:
            Tuple[Tensor, Tensor]: The labeled bounding boxes and class scores
        """
        if isinstance(x, (Path, str)):
            image = self._create_image_input(x)
            x = image * 1

        if len(x.shape) == 3:
            x = tf.expand_dims(x, 0)
        elif x.shape[0] > 1:
            raise Exception("only a single image can be operated on")
        elif len(x.shape) > 4 or len(x.shape) < 3:
            raise Exception("only a 3D or 4D tensor is allowed")

        H, W = x.shape[1:3]  # H, W
        im_size = tf.constant((H, W))
        feat_map = self.backbone(x)

        rpn_deltas, rpn_scores = self.rpn(feat_map)
        anchors = generate_anchors(
            feat_map,
            tf.constant(self.cfg["rpn"]["anchor_base_size"]),
            tf.constant(self.cfg["rpn"]["stride"]),
            tf.constant(self.cfg["rpn"]["anchor_scales"]),
            tf.constant(self.cfg["rpn"]["anchor_ratios"]),
        )

        # decode proposals
        rpn_proposals = decode(anchors, rpn_deltas)

        # filter negative area proposals and also those with low objectness score
        # for inference
        rpn_scores = rpn_scores[:, 1]
        rpn_proposals, rpn_scores = filter_proposals(
            rpn_proposals,
            rpn_scores,
            im_size,
            tf.constant(self.cfg["rpn"]["score_thresh"]),
            tf.constant(True),
        )

        # non-max-suppression
        rpn_proposals, rpn_scores = apply_nms(
            rpn_proposals,
            rpn_scores,
            tf.constant(self.cfg["rpn"]["nms_threshold"]),
            tf.constant(self.cfg["rpn"]["top_n"]),
        )

        # roi pooling
        rois = roi_pooling(
            feat_map,
            rpn_proposals,
            W,
            H,
            pool_size=tf.constant(self.cfg["rpn"]["pool_size"]),
        )

        # process roi features using backbone tail before passing to detector
        rois_feats = self.backbone(rois, part="tail")

        # detector prediction
        bbox_deltas, cls_score = self.detector(rois_feats)

        # obtain class labels and bounding boxes
        # (0 used to be the background class, hence subtract 1)
        cls_label = tf.argmax(cls_score, axis=1) - 1
        cls_label_onehot = tf.one_hot(cls_label, self.cfg["detector"]["num_classes"])
        deltas = tf.boolean_mask(
            tf.reshape(bbox_deltas, [-1, 4]), tf.reshape(cls_label_onehot, [-1])
        )
        scores = tf.boolean_mask(
            tf.reshape(cls_score[:, 1:], [-1]), tf.reshape(cls_label_onehot, [-1])
        )

        label = tf.boolean_mask(cls_label, cls_label >= 0)
        label = tf.cast(label, tf.float32)

        boxes = tf.boolean_mask(rpn_proposals, cls_label >= 0)
        bboxes = decode(boxes, deltas)

        # filter class bounding boxes with non max suppression
        if len(bboxes) > 0:
            bboxes, scores = per_class_nms(
                bboxes,
                label,
                scores,
                im_size,
                self.cfg["detector"]["score_thresh"],
                self.cfg["detector"]["nms_threshold"],
                self.cfg["detector"]["top_n"],
            )

        return image, bboxes, scores
